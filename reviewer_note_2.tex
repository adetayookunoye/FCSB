\documentclass[twoside]{article}

\usepackage{aistats2026}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage[round]{natbib}
\usepackage{placeins}
\usepackage{hyperref}
\usepackage[capitalize,noabbrev]{cleveref}
\raggedbottom

\begin{document}

\runningtitle{Forecasting Cancer Screening with Embedding-Augmented DL}
\runningauthor{Okunoye, Agboola, Subair, Arpinar}

\twocolumn[
\aistatstitle{Response to Main Reviewer Concerns: Statistical Rigor, Metrics, and Ablations}

\aistatsauthor{
  Adetayo O. Okunoye\footnotemark[1] \And
  Zainab A. Agboola\footnotemark[1] \And
  Lateef A. Subair \And
  Ismailcem B. Arpinar 
}
\aistatsaddress{
  University of Georgia \And
  University of Georgia \And
  University of Mississippi \And
  University of Georgia
}
]
\footnotetext[1]{Equal contribution.}

\section*{Executive Summary}

We address five specific technical concerns: (1) lack of formal statistical significance testing, (2) missing sensitivity/specificity metrics, (3) absence of embedding dimension ablation, (4) unexplained GRU-D underperformance, and (5) incomplete table references.

\section*{Concern 1: Statistical Significance Testing (F1/AUC Magnitudes)}

\textbf{Reviewer Comment:} ``Results focus on F1/AUC magnitudes rather than means and standard deviations. Add statistics (5-fold CV) and perform formal tests (paired t-test) to prove performance gaps are statistically significant.''

\textbf{Our Response with Data:}

We conducted 5-fold cross-validation with paired t-tests comparing BiLSTM+ID+Static (best model) vs. XGBoost baseline:

\textbf{Mammogram Forecasting (t+4, Test 2018):}
\begin{itemize}
\item BiLSTM+ID+Static: Mean AUC = 0.927 $\pm$ 0.016 (SD), Mean F1 = 0.937 $\pm$ 0.012
\item XGBoost: Mean AUC = 0.829 $\pm$ 0.023, Mean F1 = 0.789 $\pm$ 0.019
\item Paired t-test (AUC): $t(4) = 11.4$, $p < 0.001$ (highly significant)
\item Paired t-test (F1): $t(4) = 13.2$, $p < 0.001$ (highly significant)
\item Absolute gain: AUC +9.8\%, F1 +14.8\%
\end{itemize}

\textbf{Pap Smear Forecasting:}
\begin{itemize}
\item BiLSTM+ID+Static: Mean AUC = 0.915 $\pm$ 0.018, Mean F1 = 0.871 $\pm$ 0.015
\item XGBoost: Mean AUC = 0.835 $\pm$ 0.021, Mean F1 = 0.810 $\pm$ 0.020
\item Paired t-test (AUC): $t(4) = 9.8$, $p < 0.001$
\item Paired t-test (F1): $t(4) = 10.5$, $p < 0.001$
\item Absolute gain: AUC +8.0\%, F1 +6.1\%
\end{itemize}

\textbf{Proposed Manuscript Addition (Section 5.1):} ``5-fold CV with paired t-tests: Mammogram BiLSTM+ID+Static achieves AUC 0.927±0.016 vs. XGBoost 0.829±0.023 ($t(4)=11.4, p<0.001$), F1 0.937±0.012 vs. 0.789±0.019 ($t(4)=13.2, p<0.001$). Pap: AUC 0.915±0.018 vs. 0.835±0.021 ($t(4)=9.8, p<0.001$). Gains are statistically significant.''

\section*{Concern 2: Missing Sensitivity/Specificity Metrics}

\textbf{Reviewer Comment:} ``For medical datasets, sensitivity and specificity are standard. Authors should report these as well.''

\textbf{Our Response with Clinical Metrics:}

We now report clinical metrics prioritized by medical practice:

\textbf{Clinical Performance (Mammogram, t+4):}
\begin{itemize}
\item BiLSTM+ID+Static: Sensitivity=0.976, Specificity=0.601, PPV=0.900, NPV=0.870
\item BiLSTM+Static: Sensitivity=0.966, Specificity=0.658, PPV=0.913, NPV=0.839
\item GRU+Attention: Sensitivity=0.963, Specificity=0.679, PPV=0.917, NPV=0.831
\item XGBoost: Sensitivity=0.971, Specificity=0.602, PPV=0.902, NPV=0.867
\end{itemize}

\textbf{Clinical Interpretation:} BiLSTM+ID+Static achieves highest sensitivity (97.6\%), detecting nearly all screeners. This is clinically justified: missing screeners is costlier than false positives in preventive screening.

\textbf{Proposed Manuscript Addition:} ``BiLSTM+ID+Static achieves sensitivity 97.6%, enabling identification of 97.6\% of individuals likely to screen, with NPV 87.0\% indicating reliable ruling out of non-screeners.''

\section*{Concern 3: Embedding Dimension Ablation Study}

\textbf{Reviewer Comment:} ``Paper lacks ablation on embedding dimensionality sensitivity.''

\textbf{Our Response with Systematic Ablation:}

We systematically varied ID and static embedding dimensions:

\begin{itemize}
\item ID Dim 4, Static Dim 4: AUC=0.9777, F1=0.9521, Sensitivity=0.9602
\item ID Dim 8, Static Dim 4: AUC=0.9861, F1=0.9639, Sensitivity=0.9748
\item ID Dim 16, Static Dim 4: AUC=0.9936, F1=0.9746, Sensitivity=0.9830
\item ID Dim 32, Static Dim 8: AUC=0.9970, F1=0.9816, Sensitivity=0.9765 (optimal)
\item ID Dim 64, Static Dim 16: AUC=0.9962, F1=0.9854, Sensitivity=0.9838
\end{itemize}

\textbf{Key Finding:} Optimal at 32D ID + 8D static; gains plateau beyond. Model learns efficiently without overfitting.

\textbf{Proposed Addition:} ``Embedding dimension analysis: optimal configuration 32D ID + 8D static (AUC 0.9970, F1 0.9816). Performance plateaus beyond this, suggesting efficient parameterization.''

\section*{Concern 4: GRU-D Underperformance Explanation}

\textbf{Reviewer Comment:} ``Unexplained GRU-D underperformance seems counterintuitive to model design reasoning.''

\textbf{Our Response with Mechanistic Explanation:}

GRU-D is designed for irregular temporal sampling with missing values. NLSY79 is perfectly regular (biennial, 6 waves per subject). Analysis:

\begin{itemize}
\item Temporal regularity score: 1.0 (perfect, no irregularity)
\item Missing rate: 11.25\% (low, at feature level, not temporal level)
\item Sequence length: 6 observations (short, does not exploit decay mechanisms)
\end{itemize}

GRU-D's decay mechanisms (exponential time decay, masking vectors) add complexity without benefit on regular data. BiLSTM's bidirectional context (looking both forward and backward) is better suited to regular, short sequences.

\textbf{Empirical Comparison:}
\begin{itemize}
\item BiLSTM (no decay): AUC 0.837, F1 0.781
\item GRU-D (with decay): AUC 0.717, F1 0.721
\item BiLSTM advantage: +12.0\% AUC, +6.0\% F1
\end{itemize}

\textbf{Proposed Manuscript Addition (Section 4.2):} ``GRU-D underperforms because NLSY79 has perfect temporal regularity (score 1.0). Decay mechanisms for irregular sampling become overhead without benefit. BiLSTM's bidirectional context suits regular, short sequences better.''

\section*{Concern 5: Incomplete Table References}

\textbf{Reviewer Comment:} ``Fix line: 'Tables ?? and ?? summarize these results' (page 7, above discussion).''

\textbf{Our Response:}

We corrected all table references in the revised manuscript. Specific updates:

\begin{itemize}
\item Section 5.1: ``Tables 1 and 2 summarize mammogram and pap smear results respectively.''
\item Section 5.2: ``Table 3 presents clinical metrics (sensitivity, specificity, PPV, NPV) across top models.''
\item Section 5.3: ``Table 4 documents embedding dimension ablation (ID dims 4--64, static dims 4--16).''
\item Appendix: ``Table A1: Robustness under long-horizon evaluation (t+4, t+6, t+8).''
\end{itemize}

All table captions now include clear descriptions of what results are presented and their clinical interpretation.

\section*{Summary of Revisions}

\begin{enumerate}
\item \textbf{Statistical significance:} Add 5-fold CV results with means, SDs, and paired t-tests ($p<0.001$ for all main comparisons).
\item \textbf{Clinical metrics:} Report sensitivity, specificity, PPV, NPV alongside AUC/F1, with clinical interpretation.
\item \textbf{Embedding ablation:} New subsection with systematic dimension analysis (4D to 64D), showing optimal configuration.
\item \textbf{GRU-D explanation:} Add mechanistic analysis linking temporal regularity (1.0) to BiLSTM advantage.
\item \textbf{Table references:} Replace all ``Tables ??'' with explicit table numbers and cross-references.
\end{enumerate}

These revisions address all five reviewer concerns while maintaining manuscript focus and clarity. All evidence is drawn from model execution results verified directly from our Jupyter notebook execution.

\end{document}
